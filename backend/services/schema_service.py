"""
Database Schema Service
ìŠ¤í‚¤ë§ˆ ì •ë³´ ìºì‹±, LLM ë¬¸ì„œí™”, ë™ì  ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì„œë¹„ìŠ¤
"""

import json
import hashlib
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, text
from sqlalchemy.orm import selectinload

from models.models import DatabaseSchema, DatabaseConnection
from database.connection_manager import db_manager
from core.llm_providers.azure_openai_provider import AzureOpenAIProvider
from core.config import settings


class SchemaService:
    def __init__(self, session: AsyncSession):
        self.session = session
        # OpenAI ProviderëŠ” í•„ìš”í•  ë•Œë§Œ ì´ˆê¸°í™”
        self.llm_provider = None

    def _get_llm_provider(self):
        """LLM Providerë¥¼ ì§€ì—° ì´ˆê¸°í™”"""
        if self.llm_provider is None:
            try:
                config = {
                    "api_key": settings.azure_openai_api_key,
                    "endpoint": settings.azure_openai_endpoint,
                    "api_version": settings.azure_openai_api_version,
                    "deployment_name": settings.azure_openai_deployment_name
                }
                self.llm_provider = AzureOpenAIProvider(config)
            except Exception as e:
                print(f"âš ï¸ LLM Provider ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.llm_provider = None
        return self.llm_provider

    async def get_schema_info(self, user_id: str, connection_id: str, force_refresh: bool = False) -> Dict[str, Any]:
        """
        ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ìºì‹œëœ ì •ë³´ê°€ ìžˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ DBì—ì„œ ì¡°íšŒ í›„ ìºì‹±í•©ë‹ˆë‹¤.
        """
        try:
            print(f"ðŸ“‹ SchemaService.get_schema_info ì‹œìž‘: user_id={user_id}, connection_id={connection_id}")
            # 1. ìºì‹œëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ í™•ì¸
            if not force_refresh:
                cached_schema = await self._get_cached_schema(connection_id)
                if cached_schema:
                    print(f"ðŸ“‹ ìºì‹œëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì‚¬ìš©: {connection_id}")
                    return self._format_schema_response(cached_schema)

            # 2. ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ
            print(f"ðŸ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ: {connection_id}")
            raw_schema = await self._fetch_schema_from_db(user_id, connection_id)
            
            # 3. ìŠ¤í‚¤ë§ˆ í•´ì‹œ ê³„ì‚°
            schema_hash = self._calculate_schema_hash(raw_schema)
            
            # 4. ê¸°ì¡´ ìºì‹œì™€ í•´ì‹œ ë¹„êµ
            existing_schema = await self._get_cached_schema(connection_id)
            if existing_schema and existing_schema.schema_hash == schema_hash:
                print(f"âœ… ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì—†ìŒ. ê¸°ì¡´ ìºì‹œ ì‚¬ìš©: {connection_id}")
                return self._format_schema_response(existing_schema)

            # 5. LLMìœ¼ë¡œ ë¬¸ì„œí™” ìƒì„±
            print(f"ðŸ¤– LLMìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ë¬¸ì„œí™” ìƒì„± ì¤‘...")
            documentation = await self._generate_documentation(raw_schema)
            
            # 6. ìƒˆ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì €ìž¥/ì—…ë°ì´íŠ¸
            schema_record = await self._save_schema_info(
                connection_id=connection_id,
                raw_schema=raw_schema,
                schema_hash=schema_hash,
                documentation=documentation
            )
            
            print(f"ðŸ’¾ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì €ìž¥ ì™„ë£Œ: {len(raw_schema)} í…Œì´ë¸”")
            return self._format_schema_response(schema_record)
            
        except Exception as e:
            print(f"âŒ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            raise

    async def _get_cached_schema(self, connection_id: str) -> Optional[DatabaseSchema]:
        """ìºì‹œëœ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ"""
        stmt = select(DatabaseSchema).where(
            DatabaseSchema.connection_id == connection_id,
            DatabaseSchema.is_active == True
        ).order_by(DatabaseSchema.last_updated.desc())
        
        result = await self.session.execute(stmt)
        return result.scalar_one_or_none()

    async def _fetch_schema_from_db(self, user_id: str, connection_id: str) -> List[Dict[str, Any]]:
        """ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¡°íšŒ"""
        print(f"ðŸ” _fetch_schema_from_db ì‹œìž‘: connection_id={connection_id}")
        
        try:
            # ë™ì  ì—”ì§„ ìƒì„±
            engine = await db_manager.get_analysis_db_engine(connection_id, user_id)
            print(f"âœ… ì—”ì§„ ìƒì„± ì„±ê³µ")
        
            schema_info = []
            async with engine.connect() as conn:
                # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
                tables_query = """
                    SELECT table_name 
                    FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_type = 'BASE TABLE'
                    ORDER BY table_name;
                """
                
                tables_result = await conn.execute(text(tables_query))
                tables = [row[0] for row in tables_result.fetchall()]
                print(f"ðŸ“‹ í…Œì´ë¸” ë°œê²¬: {len(tables)}ê°œ")
                
                # ê° í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
                for table_name in tables:
                    columns_query = """
                        SELECT 
                            column_name,
                            data_type,
                            is_nullable,
                            column_default,
                            character_maximum_length,
                            numeric_precision,
                            numeric_scale
                        FROM information_schema.columns 
                        WHERE table_schema = 'public' 
                        AND table_name = :table_name
                        ORDER BY ordinal_position;
                    """
                    
                    columns_result = await conn.execute(text(columns_query), {"table_name": table_name})
                    columns = []
                    
                    for row in columns_result.fetchall():
                        column_info = {
                            "column_name": row[0],
                            "data_type": row[1],
                            "is_nullable": row[2] == "YES",
                            "column_default": row[3],
                            "max_length": row[4],
                            "numeric_precision": row[5],
                            "numeric_scale": row[6]
                        }
                        columns.append(column_info)
                    
                    table_info = {
                        "table_name": table_name,
                        "columns": columns,
                        "column_count": len(columns)
                    }
                    schema_info.append(table_info)
            
            await engine.dispose()
            print(f"âœ… ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì™„ë£Œ: {len(schema_info)}ê°œ í…Œì´ë¸”")
            return schema_info
            
        except Exception as e:
            print(f"âŒ _fetch_schema_from_db ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            raise

    def _calculate_schema_hash(self, schema_data: List[Dict[str, Any]]) -> str:
        """ìŠ¤í‚¤ë§ˆ ë°ì´í„°ì˜ í•´ì‹œê°’ ê³„ì‚° (ë³€ê²½ ê°ì§€ìš©)"""
        schema_structure = []
        for table in schema_data:
            table_structure = {
                "table_name": table["table_name"],
                "columns": [
                    {
                        "column_name": col["column_name"],
                        "data_type": col["data_type"],
                        "is_nullable": col["is_nullable"]
                    }
                    for col in table["columns"]
                ]
            }
            schema_structure.append(table_structure)
        
        schema_json = json.dumps(schema_structure, sort_keys=True)
        return hashlib.sha256(schema_json.encode()).hexdigest()

    async def _generate_documentation(self, schema_data: List[Dict[str, Any]]) -> str:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ë¬¸ì„œí™” ìƒì„±"""
        try:
            schema_summary = self._create_schema_summary(schema_data)
            
            prompt = f"""ë‹¤ìŒì€ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ìž…ë‹ˆë‹¤. ì‚¬ìš©ìžê°€ ì±„íŒ… ì‹œ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•  ë•Œ ì •í™•í•œ SQLì„ ìƒì„±í•  ìˆ˜ ìžˆë„ë¡ í•œêµ­ì–´ ë§¤í•‘ ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ì„œë¥¼ ìž‘ì„±í•´ì£¼ì„¸ìš”.

í•µì‹¬ ëª©ì : 
- ì‚¬ìš©ìžëŠ” "ê³ ê°ë³„ ì£¼ë¬¸ ê±´ìˆ˜", "ìƒí’ˆ íŒë§¤ëŸ‰", "ì›”ë³„ ë§¤ì¶œ" ë“± í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•©ë‹ˆë‹¤
- ì´ ë¬¸ì„œì˜ í•œêµ­ì–´ í…Œì´ë¸”ëª…/ì»¬ëŸ¼ëª… ë§¤í•‘ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ LLMì´ ì •í™•í•œ SQLì„ ìž‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤

ìš”êµ¬ ì‚¬í•­:
1. ëª¨ë“  í…Œì´ë¸” ì„¹ì…˜ì€ ì•„ëž˜ ì˜ˆì‹œì™€ ê°™ì€ **JSON-ìœ ì‚¬ ë§ˆí¬ë‹¤ìš´ ë¸”ë¡**ìœ¼ë¡œ ìž‘ì„±í•˜ì„¸ìš”.
2. `koreanName` í•„ë“œì— í…Œì´ë¸”ì˜ ì •í™•í•œ í•œêµ­ì–´ ëª…ì¹­ì„ ê¸°ë¡í•˜ì„¸ìš”.
3. `columns` ë°°ì—´ì˜ ê° ì»¬ëŸ¼ì— `koreanName`ê³¼ `description`ì„ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”.
4. `keywords` ë°°ì—´ì— ì‚¬ìš©ìžê°€ ì´ í…Œì´ë¸”/ì»¬ëŸ¼ì„ ì–¸ê¸‰í•  ë•Œ ì‚¬ìš©í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ í•œêµ­ì–´ í‚¤ì›Œë“œë“¤ì„ ë‚˜ì—´í•˜ì„¸ìš”.
5. `sqlMappings` í•„ë“œì— ìžì£¼ ì‚¬ìš©ë  í•œêµ­ì–´ ì§ˆë¬¸ íŒ¨í„´ê³¼ í•´ë‹¹ SQL ížŒíŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.

ì˜ˆì‹œ í˜•ì‹:
```jsonc
{
  "name": "orders",
  "koreanName": "ì£¼ë¬¸",
  "displayName": "ðŸ›’ ì£¼ë¬¸ (Orders)",
  "description": "ê³ ê° ì£¼ë¬¸ ì •ë³´ ë° ë°°ì†¡ ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” í•µì‹¬ í…Œì´ë¸”",
  "relation": "customers.customerid â†’ orders.customerid (ê³ ê°-ì£¼ë¬¸ ê´€ê³„)",
  "keywords": ["ì£¼ë¬¸", "ì˜¤ë”", "êµ¬ë§¤", "êµ¬ìž…", "ê²°ì œ"],
  "columns": [
    { 
      "name": "orderid", 
      "type": "INTEGER", 
      "koreanName": "ì£¼ë¬¸ë²ˆí˜¸",
      "description": "ê° ì£¼ë¬¸ì„ ê³ ìœ í•˜ê²Œ ì‹ë³„í•˜ëŠ” ê¸°ë³¸í‚¤",
      "keywords": ["ì£¼ë¬¸ë²ˆí˜¸", "ì£¼ë¬¸ID", "ì˜¤ë”ë²ˆí˜¸"]
    },
    { 
      "name": "customerid", 
      "type": "INTEGER", 
      "koreanName": "ê³ ê°ë²ˆí˜¸",
      "description": "ì£¼ë¬¸í•œ ê³ ê°ì„ ì‹ë³„í•˜ëŠ” ì™¸ëž˜í‚¤",
      "keywords": ["ê³ ê°ë²ˆí˜¸", "ê³ ê°ID", "êµ¬ë§¤ìž"]
    },
    { 
      "name": "orderdate", 
      "type": "DATE", 
      "koreanName": "ì£¼ë¬¸ì¼ìž",
      "description": "ì£¼ë¬¸ì´ ì ‘ìˆ˜ëœ ë‚ ì§œ",
      "keywords": ["ì£¼ë¬¸ì¼", "ì£¼ë¬¸ë‚ ì§œ", "êµ¬ë§¤ì¼", "êµ¬ìž…ì¼"]
    }
  ],
  "sqlMappings": [
    {
      "koreanQuestion": "ê³ ê°ë³„ ì£¼ë¬¸ ê±´ìˆ˜",
      "sqlHint": "SELECT customerid, COUNT(*) FROM orders GROUP BY customerid"
    },
    {
      "koreanQuestion": "ì›”ë³„ ì£¼ë¬¸ëŸ‰",
      "sqlHint": "SELECT EXTRACT(MONTH FROM orderdate), COUNT(*) FROM orders GROUP BY EXTRACT(MONTH FROM orderdate)"
    }
  ],
  "examples": [
    { "question": "ì´ë²ˆ ë‹¬ ì£¼ë¬¸ ìˆ˜ëŠ”?", "purpose": "ìµœê·¼ íŒë§¤ ì‹¤ì  í™•ì¸" },
    { "question": "ê°€ìž¥ ë§Žì´ ì£¼ë¬¸í•œ ê³ ê°ì€?", "purpose": "VIP ê³ ê° ë¶„ì„" }
  ]
}
```
ìœ„ì™€ ê°™ì€ ë¸”ë¡ì„ í…Œì´ë¸”ë³„ë¡œ ë‚˜ì—´í•˜ë˜, ë°˜ë“œì‹œ í•œêµ­ì–´ ë§¤í•‘ ì •ë³´(`koreanName`, `keywords`, `sqlMappings`)ë¥¼ ì •í™•í•˜ê²Œ í¬í•¨í•˜ì„¸ìš”.

ìŠ¤í‚¤ë§ˆ ìš”ì•½:
{schema_summary}
"""

            llm_provider = self._get_llm_provider()
            if llm_provider:
                await llm_provider.initialize()
                
                messages = [
                    {"role": "user", "content": prompt}
                ]
                
                response = await llm_provider.generate_chat_completion(
                    messages=messages,
                    max_tokens=2000,
                    temperature=0.3
                )
                
                return response
            else:
                print("âš ï¸ LLM Providerë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ - ê¸°ë³¸ ë¬¸ì„œí™” ìƒì„±")
                return self._create_fallback_documentation(schema_data)
            
        except Exception as e:
            print(f"âš ï¸ LLM ë¬¸ì„œí™” ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return self._create_fallback_documentation(schema_data)

    def _create_schema_summary(self, schema_data: List[Dict[str, Any]]) -> str:
        """ìŠ¤í‚¤ë§ˆ ë°ì´í„°ë¥¼ LLMìš© ìš”ì•½ìœ¼ë¡œ ë³€í™˜"""
        summary_parts = []
        
        for table in schema_data:
            table_name = table["table_name"]
            columns = table["columns"]
            
            column_info = []
            for col in columns:
                col_desc = f"{col['column_name']} ({col['data_type']}"
                if not col['is_nullable']:
                    col_desc += ", NOT NULL"
                col_desc += ")"
                column_info.append(col_desc)
            
            table_summary = f"""í…Œì´ë¸”: {table_name}
ì»¬ëŸ¼ ìˆ˜: {len(columns)}
ì»¬ëŸ¼ ëª©ë¡: {', '.join(column_info)}"""
            summary_parts.append(table_summary)
        
        return "\n\n".join(summary_parts)

    def _create_fallback_documentation(self, schema_data: List[Dict[str, Any]]) -> str:
        """LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¬¸ì„œí™” - í•œêµ­ì–´ ë§¤í•‘ ì •ë³´ í¬í•¨"""
        blocks = []
        for table in schema_data:
            table_name = table["table_name"]
            
            # ê¸°ë³¸ì ì¸ í•œêµ­ì–´ í…Œì´ë¸”ëª… ì¶”ì •
            korean_table_name = self._guess_korean_table_name(table_name)
            
            # ì»¬ëŸ¼ ì •ë³´ ë°°ì—´ êµ¬ì„±
            cols_arr = []
            for col in table["columns"]:
                korean_col_name = self._guess_korean_column_name(col["column_name"])
                keywords = self._generate_basic_keywords(korean_col_name, col["column_name"])
                
                col_desc = {
                    "name": col["column_name"],
                    "type": col["data_type"],
                    "koreanName": korean_col_name,
                    "description": f"{korean_col_name} ({'NOT NULL' if not col['is_nullable'] else 'NULL í—ˆìš©'})",
                    "keywords": keywords
                }
                cols_arr.append(col_desc)

            # ê¸°ë³¸ SQL ë§¤í•‘ ìƒì„±
            sql_mappings = [
                {
                    "koreanQuestion": f"{korean_table_name} ì „ì²´ ê±´ìˆ˜",
                    "sqlHint": f"SELECT COUNT(*) FROM {table_name}"
                },
                {
                    "koreanQuestion": f"{korean_table_name} ëª©ë¡ ì¡°íšŒ",
                    "sqlHint": f"SELECT * FROM {table_name} LIMIT 10"
                }
            ]

            block = {
                "name": table_name,
                "koreanName": korean_table_name,
                "displayName": f"ðŸ“Š {korean_table_name} ({table_name})",
                "description": f"{korean_table_name} ì •ë³´ë¥¼ ì €ìž¥í•˜ëŠ” í…Œì´ë¸”",
                "relation": "ìžë™ ë¶„ì„ ë¶ˆê°€",
                "keywords": [korean_table_name, table_name],
                "columns": cols_arr,
                "sqlMappings": sql_mappings,
                "examples": [
                    {"question": f"{korean_table_name} ìˆ˜ëŠ”?", "purpose": "ë°ì´í„° ê·œëª¨ í™•ì¸"}
                ]
            }
            import json
            blocks.append("```jsonc\n" + json.dumps(block, ensure_ascii=False, indent=2) + "\n```")

        return "\n\n".join(blocks)
    
    def _guess_korean_table_name(self, table_name: str) -> str:
        """í…Œì´ë¸”ëª…ìœ¼ë¡œë¶€í„° ê¸°ë³¸ì ì¸ í•œêµ­ì–´ëª… ì¶”ì •"""
        name_mapping = {
            "users": "ì‚¬ìš©ìž", "user": "ì‚¬ìš©ìž",
            "customers": "ê³ ê°", "customer": "ê³ ê°",
            "orders": "ì£¼ë¬¸", "order": "ì£¼ë¬¸",
            "products": "ìƒí’ˆ", "product": "ìƒí’ˆ",
            "items": "í’ˆëª©", "item": "í’ˆëª©",
            "sales": "íŒë§¤", "sale": "íŒë§¤",
            "employees": "ì§ì›", "employee": "ì§ì›",
            "categories": "ë¶„ë¥˜", "category": "ë¶„ë¥˜",
            "invoices": "ì²­êµ¬ì„œ", "invoice": "ì²­êµ¬ì„œ",
            "payments": "ê²°ì œ", "payment": "ê²°ì œ",
            "shipments": "ë°°ì†¡", "shipment": "ë°°ì†¡",
            "suppliers": "ê³µê¸‰ì—…ì²´", "supplier": "ê³µê¸‰ì—…ì²´"
        }
        
        table_lower = table_name.lower()
        for eng, kor in name_mapping.items():
            if eng in table_lower:
                return kor
        
        return table_name  # ë§¤í•‘ë˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    
    def _guess_korean_column_name(self, column_name: str) -> str:
        """ì»¬ëŸ¼ëª…ìœ¼ë¡œë¶€í„° ê¸°ë³¸ì ì¸ í•œêµ­ì–´ëª… ì¶”ì •"""
        name_mapping = {
            "id": "ë²ˆí˜¸", "_id": "ë²ˆí˜¸",
            "name": "ì´ë¦„", "title": "ì œëª©",
            "date": "ë‚ ì§œ", "time": "ì‹œê°„",
            "price": "ê°€ê²©", "cost": "ë¹„ìš©", "amount": "ê¸ˆì•¡",
            "quantity": "ìˆ˜ëŸ‰", "count": "ê±´ìˆ˜",
            "address": "ì£¼ì†Œ", "email": "ì´ë©”ì¼", "phone": "ì „í™”ë²ˆí˜¸",
            "status": "ìƒíƒœ", "type": "ìœ í˜•",
            "created": "ìƒì„±ì¼", "updated": "ìˆ˜ì •ì¼",
            "description": "ì„¤ëª…", "note": "ë©”ëª¨"
        }
        
        col_lower = column_name.lower()
        for eng, kor in name_mapping.items():
            if eng in col_lower:
                return kor
        
        return column_name  # ë§¤í•‘ë˜ì§€ ì•Šìœ¼ë©´ ì›ë³¸ ë°˜í™˜
    
    def _generate_basic_keywords(self, korean_name: str, english_name: str) -> List[str]:
        """ê¸°ë³¸ì ì¸ í‚¤ì›Œë“œ ëª©ë¡ ìƒì„±"""
        keywords = [korean_name, english_name]
        
        # ì¼ë°˜ì ì¸ ë™ì˜ì–´ ì¶”ê°€
        synonym_map = {
            "ë²ˆí˜¸": ["ID", "ì•„ì´ë””", "ì‹ë³„ìž"],
            "ì´ë¦„": ["ëª…ì¹­", "ë„¤ìž„"],
            "ë‚ ì§œ": ["ì¼ìž", "ì¼ì‹œ"],
            "ê°€ê²©": ["ë‹¨ê°€", "ë¹„ìš©", "ê¸ˆì•¡"],
            "ìˆ˜ëŸ‰": ["ê°œìˆ˜", "ì–‘", "ëŸ‰"],
            "ê³ ê°": ["êµ¬ë§¤ìž", "í´ë¼ì´ì–¸íŠ¸"],
            "ì£¼ë¬¸": ["ì˜¤ë”", "êµ¬ë§¤", "êµ¬ìž…"],
            "ìƒí’ˆ": ["ì œí’ˆ", "ì•„ì´í…œ", "ìƒì˜¤"]
        }
        
        if korean_name in synonym_map:
            keywords.extend(synonym_map[korean_name])
        
        return list(set(keywords))  # ì¤‘ë³µ ì œê±°

    async def _save_schema_info(
        self,
        connection_id: str,
        raw_schema: List[Dict[str, Any]],
        schema_hash: str,
        documentation: str
    ) -> DatabaseSchema:
        """ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥"""
        
        # ê¸°ì¡´ í™œì„± ìŠ¤í‚¤ë§ˆ ë¹„í™œì„±í™”
        stmt = select(DatabaseSchema).where(
            DatabaseSchema.connection_id == connection_id,
            DatabaseSchema.is_active == True
        )
        result = await self.session.execute(stmt)
        existing_schemas = result.scalars().all()
        
        for schema in existing_schemas:
            schema.is_active = False
        
        # ìƒˆ ìŠ¤í‚¤ë§ˆ ë ˆì½”ë“œ ìƒì„±
        total_columns = sum(len(table["columns"]) for table in raw_schema)
        
        new_schema = DatabaseSchema(
            connection_id=connection_id,
            schema_hash=schema_hash,
            raw_schema=raw_schema,
            generated_documentation=documentation,
            table_count=len(raw_schema),
            total_columns=total_columns,
            last_updated=datetime.now(timezone.utc),
            created_at=datetime.now(timezone.utc),
            is_active=True
        )
        
        self.session.add(new_schema)
        await self.session.commit()
        await self.session.refresh(new_schema)
        
        return new_schema

    def _format_schema_response(self, schema_record: DatabaseSchema) -> Dict[str, Any]:
        """ìŠ¤í‚¤ë§ˆ ë ˆì½”ë“œë¥¼ API ì‘ë‹µ í˜•íƒœë¡œ ë³€í™˜"""
        return {
            "schema_id": schema_record.id,
            "connection_id": schema_record.connection_id,
            "table_count": schema_record.table_count,
            "total_columns": schema_record.total_columns,
            "last_updated": schema_record.last_updated.isoformat(),
            "tables": schema_record.raw_schema,
            "documentation": schema_record.generated_documentation,
            "schema_hash": schema_record.schema_hash
        }

    async def refresh_schema(self, user_id: str, connection_id: str) -> Dict[str, Any]:
        """ê°•ì œë¡œ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤."""
        return await self.get_schema_info(user_id=user_id, connection_id=connection_id, force_refresh=True)
