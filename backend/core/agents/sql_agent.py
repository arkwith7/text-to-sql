"""
Enhanced SQL Agent for Text-to-SQL application.
Handles natural language to SQL conversion and execution with PostgreSQL Northwind optimization.
"""

import logging
import time
import re
import uuid
from typing import Dict, Any, Optional, List, Tuple

from .base_agent import BaseAgent

logger = logging.getLogger(__name__)


class SQLAgent(BaseAgent):
    """Enhanced SQL Agent with PostgreSQL Northwind optimization and advanced features."""
    
    def __init__(self, db_manager=None):
        """Initialize Enhanced SQL Agent with database manager."""
        super().__init__(db_manager)
        self.logger = logging.getLogger(__name__)
        
        # Token usage service ì´ˆê¸°í™” (ì§€ì—° import)
        self.db_manager = db_manager
        self.token_usage_service = None
        
        # ë…¸íŠ¸ë¶ì˜ AdvancedSQLGenerator ê¸°ëŠ¥ ì¶”ê°€
        self.generation_stats = {
            'total_requests': 0,
            'pattern_matches': 0,
            'llm_generations': 0,
            'successful_generations': 0,
            'failed_generations': 0
        }
        
        # PostgreSQL Northwind ìµœì í™”ëœ ì¿¼ë¦¬ íŒ¨í„´
        self.query_patterns = {
            # ê¸°ë³¸ COUNT ì¿¼ë¦¬ë“¤
            r'ê³ ê°\s*ìˆ˜': 'SELECT COUNT(*) as customer_count FROM customers',
            r'ì œí’ˆ\s*ìˆ˜': 'SELECT COUNT(*) as product_count FROM products',
            r'ì£¼ë¬¸\s*ìˆ˜': 'SELECT COUNT(*) as order_count FROM orders',
            r'ì¹´í…Œê³ ë¦¬\s*ìˆ˜': 'SELECT COUNT(*) as category_count FROM categories',
            r'ì§ì›\s*ìˆ˜': 'SELECT COUNT(*) as employee_count FROM employees',
            
            # ì˜ì–´ COUNT ì¿¼ë¦¬ë“¤
            r'how\s+many\s+customers': 'SELECT COUNT(*) as customer_count FROM customers',
            r'how\s+many\s+products': 'SELECT COUNT(*) as product_count FROM products',
            r'customer\s+count': 'SELECT COUNT(*) as customer_count FROM customers',
            
            # ê¸°ë³¸ ì¡°íšŒ ì¿¼ë¦¬ë“¤
            r'ê³ ê°\s*ëª©ë¡': 'SELECT customerid, customername, country FROM customers LIMIT 20',
            r'ì œí’ˆ\s*ëª©ë¡': 'SELECT productid, productname, price FROM products LIMIT 20',
            r'ì£¼ë¬¸\s*ëª©ë¡': 'SELECT orderid, customerid, orderdate FROM orders ORDER BY orderdate DESC LIMIT 20',
            r'ì¹´í…Œê³ ë¦¬\s*ëª©ë¡': 'SELECT categoryid, categoryname, description FROM categories',
            
            # ë…¸íŠ¸ë¶ì˜ ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¿¼ë¦¬ íŒ¨í„´ ì¶”ê°€
            r'ì¹´í…Œê³ ë¦¬ë³„\s*ì œí’ˆ\s*ìˆ˜': '''SELECT c.categoryname, COUNT(p.productid) as product_count 
                FROM categories c 
                LEFT JOIN products p ON c.categoryid = p.categoryid 
                GROUP BY c.categoryname, c.categoryid 
                ORDER BY product_count DESC''',
                
            r'ì¹´í…Œê³ ë¦¬ë³„\s*ë§¤ì¶œ': '''SELECT c.categoryname, 
                ROUND(SUM(od.unitprice * od.quantity * (1 - od.discount)), 2) as total_sales
                FROM categories c
                JOIN products p ON c.categoryid = p.categoryid
                JOIN orderdetails od ON p.productid = od.productid
                GROUP BY c.categoryname, c.categoryid
                ORDER BY total_sales DESC''',
                
            r'ì¸ê¸°\s*ì œí’ˆ': '''SELECT p.productname, SUM(od.quantity) as total_quantity
                FROM products p
                JOIN orderdetails od ON p.productid = od.productid
                GROUP BY p.productname, p.productid
                ORDER BY total_quantity DESC
                LIMIT 10''',
            
            # ì˜ì–´ íŒ¨í„´
            r'show\s+customers': 'SELECT customerid, customername, country FROM customers LIMIT 20',
            r'show\s+products': 'SELECT productid, productname, price FROM products LIMIT 20',
            r'list\s+customers': 'SELECT customerid, customername, country FROM customers LIMIT 20'
        }
        
        self.logger.info(f"Enhanced SQL Agent ì´ˆê¸°í™” ì™„ë£Œ - {len(self.query_patterns)}ê°œ íŒ¨í„´ ë¡œë“œë¨")
    
    def _get_token_usage_service(self):
        """í† í° ì‚¬ìš©ëŸ‰ ì„œë¹„ìŠ¤ë¥¼ ì§€ì—° ë¡œë”©í•©ë‹ˆë‹¤."""
        if self.token_usage_service is None and self.db_manager:
            try:
                from services.token_usage_service import TokenUsageService
                self.token_usage_service = TokenUsageService(self.db_manager)
                self.logger.info("âœ… Token Usage Service ì—°ë™ ì™„ë£Œ")
            except ImportError as e:
                self.logger.warning(f"Token Usage Service ë¡œë”© ì‹¤íŒ¨: {e}")
        return self.token_usage_service
    
    def _generate_sql(self, question: str) -> Tuple[str, str]:
        """ìì—°ì–´ ì§ˆë¬¸ì„ SQLë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        question_lower = question.lower().strip()
        self.logger.debug(f"SQL ìƒì„± ì‹œì‘: '{question}'")
        
        # íŒ¨í„´ ë§¤ì¹­
        for pattern, sql_template in self.query_patterns.items():
            if re.search(pattern, question_lower, re.IGNORECASE):
                self.logger.debug(f"íŒ¨í„´ ë§¤ì¹˜: {pattern}")
                sql_query = sql_template.strip()
                explanation = self._get_explanation_for_pattern(pattern, question)
                return sql_query, explanation
        
        # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ fallback
        return self._get_fallback_query(question_lower)
    
    def _get_explanation_for_pattern(self, pattern: str, question: str) -> str:
        """íŒ¨í„´ì— ëŒ€í•œ í•œêµ­ì–´ ì„¤ëª… ìƒì„±"""
        if 'ê³ ê°' in pattern or 'customer' in pattern:
            return 'ê³ ê° ê´€ë ¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.'
        elif 'ì œí’ˆ' in pattern or 'product' in pattern:
            return 'ì œí’ˆ ê´€ë ¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.'
        elif 'ì£¼ë¬¸' in pattern or 'order' in pattern:
            return 'ì£¼ë¬¸ ê´€ë ¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.'
        elif 'ì¹´í…Œê³ ë¦¬' in pattern:
            return 'ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.'
        else:
            return f"'{question}'ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."
    
    def _get_fallback_query(self, question_lower: str) -> Tuple[str, str]:
        """íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ fallback ì¿¼ë¦¬ ìƒì„±"""
        if any(word in question_lower for word in ['customer', 'customers', 'ê³ ê°']):
            return (
                'SELECT customerid, customername, country FROM customers LIMIT 10',
                'ê³ ê° ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.'
            )
        elif any(word in question_lower for word in ['product', 'products', 'ì œí’ˆ', 'ìƒí’ˆ']):
            return (
                'SELECT productid, productname, price FROM products LIMIT 10',
                'ì œí’ˆ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.'
            )
        elif any(word in question_lower for word in ['order', 'orders', 'ì£¼ë¬¸']):
            return (
                'SELECT orderid, customerid, orderdate FROM orders ORDER BY orderdate DESC LIMIT 10',
                'ìµœê·¼ ì£¼ë¬¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.'
            )
        else:
            return (
                "SELECT 'PostgreSQL Northwind ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. ì˜ˆ: ê³ ê° ìˆ˜, ì œí’ˆ ìˆ˜' as message",
                'ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.'
            )

    # === ë…¸íŠ¸ë¶ì˜ AdvancedSQLGenerator í†µê³„ ê´€ë¦¬ ê¸°ëŠ¥ ===
    
    def get_generation_stats(self) -> Dict[str, Any]:
        """SQL ìƒì„± í†µê³„ ë°˜í™˜ (ë…¸íŠ¸ë¶ AdvancedSQLGenerator ê¸°ëŠ¥)"""
        stats = self.generation_stats.copy()
        if stats['total_requests'] > 0:
            stats['pattern_match_rate'] = round(stats['pattern_matches'] / stats['total_requests'] * 100, 1)
            stats['llm_success_rate'] = round(stats['successful_generations'] / max(stats['llm_generations'], 1) * 100, 1) if stats['llm_generations'] > 0 else 0
        else:
            stats['pattern_match_rate'] = 0
            stats['llm_success_rate'] = 0
        
        return stats
    
    def reset_generation_stats(self):
        """SQL ìƒì„± í†µê³„ ì´ˆê¸°í™”"""
        self.generation_stats = {
            'total_requests': 0,
            'pattern_matches': 0,
            'llm_generations': 0,
            'successful_generations': 0,
            'failed_generations': 0
        }
        self.logger.info("ğŸ”„ SQL ìƒì„± í†µê³„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_supported_patterns(self) -> List[str]:
        """ì§€ì›ë˜ëŠ” ì¿¼ë¦¬ íŒ¨í„´ ëª©ë¡ ë°˜í™˜"""
        patterns = []
        for pattern in self.query_patterns.keys():
            # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜
            readable_pattern = pattern.replace(r'\s*', ' ').replace(r'\s+', ' ')
            patterns.append(readable_pattern)
        return patterns
    
    def _execute_simulated_query(self, sql_query: str, max_rows: Optional[int] = None) -> List[Dict[str, Any]]:
        """ì‹œë®¬ë ˆì´ì…˜ëœ ì¿¼ë¦¬ ì‹¤í–‰ (ë…¸íŠ¸ë¶ì˜ ì‹¤ì œ Northwind ë°ì´í„° ìˆ˜ì¹˜ ë°˜ì˜)"""
        sql_upper = sql_query.upper().strip()
        
        # COUNT ì¿¼ë¦¬ ì²˜ë¦¬ (ë…¸íŠ¸ë¶ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ë°ì´í„° ìˆ˜ì¹˜)
        if "COUNT(*)" in sql_upper:
            if "CUSTOMERS" in sql_upper:
                return [{"customer_count": 91}]  # ì‹¤ì œ Northwind DB ìˆ˜ì¹˜
            elif "PRODUCTS" in sql_upper:
                return [{"product_count": 77}]   # ì‹¤ì œ Northwind DB ìˆ˜ì¹˜
            elif "ORDERS" in sql_upper:
                return [{"order_count": 830}]    # ì‹¤ì œ Northwind DB ìˆ˜ì¹˜ (ë…¸íŠ¸ë¶ì—ì„œ í™•ì¸)
            elif "CATEGORIES" in sql_upper:
                return [{"category_count": 8}]
            elif "EMPLOYEES" in sql_upper:
                return [{"employee_count": 9}]   # ì‹¤ì œ Northwind DB ìˆ˜ì¹˜
            else:
                return [{"count": 0}]
        
        # ë³µì¡í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì¿¼ë¦¬ ì²˜ë¦¬ (ë…¸íŠ¸ë¶ íŒ¨í„´)
        elif "GROUP BY" in sql_upper:
            if "CATEGORYNAME" in sql_upper and "PRODUCT_COUNT" in sql_upper:
                # ì¹´í…Œê³ ë¦¬ë³„ ì œí’ˆ ìˆ˜
                return [
                    {"categoryname": "Beverages", "product_count": 12},
                    {"categoryname": "Condiments", "product_count": 12},
                    {"categoryname": "Dairy Products", "product_count": 10},
                    {"categoryname": "Grains/Cereals", "product_count": 7},
                    {"categoryname": "Meat/Poultry", "product_count": 6},
                    {"categoryname": "Produce", "product_count": 5},
                    {"categoryname": "Seafood", "product_count": 12},
                    {"categoryname": "Confections", "product_count": 13}
                ]
            elif "TOTAL_SALES" in sql_upper:
                # ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ
                return [
                    {"categoryname": "Beverages", "total_sales": 267868.20},
                    {"categoryname": "Dairy Products", "total_sales": 234507.30},
                    {"categoryname": "Confections", "total_sales": 167357.26},
                    {"categoryname": "Meat/Poultry", "total_sales": 163022.37},
                    {"categoryname": "Seafood", "total_sales": 131261.75}
                ]
            elif "TOTAL_QUANTITY" in sql_upper:
                # ì¸ê¸° ì œí’ˆ
                return [
                    {"productname": "Camembert Pierrot", "total_quantity": 1577},
                    {"productname": "Raclette Courdavault", "total_quantity": 1496},
                    {"productname": "Gorgonzola Telino", "total_quantity": 1397},
                    {"productname": "Chartreuse verte", "total_quantity": 1158},
                    {"productname": "CÃ´te de Blaye", "total_quantity": 623}
                ]
        
        # ê¸°ë³¸ í…Œì´ë¸” ì¡°íšŒ
        elif "SELECT" in sql_upper:
            if "CUSTOMERS" in sql_upper:
                return [
                    {"customerid": "ALFKI", "customername": "Alfreds Futterkiste", "country": "Germany"},
                    {"customerid": "ANATR", "customername": "Ana Trujillo Emparedados y helados", "country": "Mexico"},
                    {"customerid": "ANTON", "customername": "Antonio Moreno TaquerÃ­a", "country": "Mexico"}
                ]
            elif "PRODUCTS" in sql_upper:
                return [
                    {"productid": 1, "productname": "Chai", "price": 18.00},
                    {"productid": 2, "productname": "Chang", "price": 19.00},
                    {"productid": 3, "productname": "Aniseed Syrup", "price": 10.00}
                ]
            elif "CATEGORIES" in sql_upper:
                return [
                    {"categoryid": 1, "categoryname": "Beverages", "description": "Soft drinks, coffees, teas, beers, and ales"},
                    {"categoryid": 2, "categoryname": "Condiments", "description": "Sweet and savory sauces, relishes, spreads, and seasonings"},
                    {"categoryid": 3, "categoryname": "Dairy Products", "description": "Cheeses"}
                ]
        
        # ë©”ì‹œì§€ ì¿¼ë¦¬
        return [{"message": "PostgreSQL Northwind ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."}]
    
    def execute_query_sync(
        self,
        question: str,
        database: str = "northwind",
        include_explanation: bool = True,
        max_rows: Optional[int] = None,
        include_metadata: bool = False
    ) -> Dict[str, Any]:
        """ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤ (ë…¸íŠ¸ë¶ AdvancedSQLGenerator ê¸°ëŠ¥ í¬í•¨)."""
        start_time = time.time()
        
        try:
            # ë©”íƒ€ë°ì´í„° í¬í•¨ SQL ìƒì„±
            if include_metadata:
                sql_query, explanation, metadata = self._generate_sql_with_metadata(question)
            else:
                sql_query, explanation = self._generate_sql(question)
                metadata = {}
            
            # ì‹œë®¬ë ˆì´ì…˜ëœ ê²°ê³¼ ì‹¤í–‰
            results = self._execute_simulated_query(sql_query, max_rows)
            
            execution_time = time.time() - start_time
            
            self.logger.info(
                f"ë™ê¸° ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ - ì‹œê°„: {execution_time:.3f}s, ê²°ê³¼: {len(results)}í–‰"
            )
            
            response = {
                "success": True,
                "sql_query": sql_query,
                "results": results,
                "row_count": len(results),
                "execution_time": execution_time,
                "database": database,
                "question": question,
                "token_usage": {  # Enhanced SQL AgentëŠ” LLMì„ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ í† í° ì‚¬ìš©ëŸ‰ì€ 0
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                }
            }
            
            if include_explanation:
                response["explanation"] = explanation
                
            if include_metadata and metadata:
                response["metadata"] = metadata
                response["generation_method"] = metadata.get('method', 'unknown')
                response["sql_complexity"] = metadata.get('complexity', 'simple')
                
            return response
            
        except Exception as e:
            execution_time = time.time() - start_time
            error_msg = str(e)
            
            self.logger.error(f"ë™ê¸° ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {error_msg}")
            
            return {
                "success": False,
                "error": error_msg,
                "execution_time": execution_time,
                "question": question,
                "database": database,
                "results": [],
                "row_count": 0,
                "token_usage": {  # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ í† í° ì •ë³´ í¬í•¨
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                }
            }
    
    async def execute_query(
        self,
        question: str,
        engine, # SQLAlchemy AsyncEngine
        context: Optional[str] = None,
        user_id: Optional[int] = None,
        include_explanation: bool = True,
        include_debug_info: bool = False,
        max_rows: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        Processes a natural language query using a dynamically provided database engine.
        """
        start_time = time.time()
        query_id = str(uuid.uuid4())
        
        # 1. Generate SQL from the question (currently pattern-based)
        sql_query, explanation = self._generate_sql(question)
        
        # If the generated SQL is just a message, return it directly
        if "SELECT '" in sql_query:
            return {
                "success": False,
                "question": question,
                "sql_query": sql_query,
                "results": [{"message": explanation}],
                "explanation": explanation,
                "execution_time": time.time() - start_time,
                "row_count": 1,
                "token_usage": None
            }
        
        # 2. Execute the SQL query using the provided engine
        results = []
        error_message = None
        success = False
        try:
            async with engine.connect() as connection:
                result_proxy = await connection.execute(sql_query)
                results = [dict(row) for row in result_proxy.fetchall()]
                if max_rows and len(results) > max_rows:
                    results = results[:max_rows]
                success = True
            self.logger.info(f"Query executed successfully on dynamic engine. Rows: {len(results)}")
        except Exception as e:
            error_message = f"Error executing SQL: {str(e)}"
            self.logger.error(error_message)
            success = False

        execution_time = time.time() - start_time

        # Token usage would be calculated if an LLM was used for generation
        token_usage = { "prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0 }

        return {
            "success": success,
            "question": question,
            "sql_query": sql_query,
            "results": results,
            "explanation": explanation if include_explanation else None,
            "execution_time": execution_time,
            "row_count": len(results),
            "error_message": error_message,
            "token_usage": token_usage,
            "query_id": query_id
        }
    
    async def validate_query(
        self,
        sql_query: str,
        database: str = "northwind"
    ) -> Dict[str, Any]:
        """SQL ì¿¼ë¦¬ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
        try:
            sql_upper = sql_query.upper().strip()
            
            # ìœ„í—˜í•œ í‚¤ì›Œë“œ ê²€ì‚¬
            dangerous_keywords = ['DROP', 'DELETE', 'TRUNCATE', 'ALTER', 'CREATE', 'UPDATE', 'INSERT']
            for keyword in dangerous_keywords:
                if keyword in sql_upper:
                    return {
                        "is_valid": False,
                        "error_message": f"'{keyword}' í‚¤ì›Œë“œëŠ” í—ˆìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                        "suggestions": ["SELECT ì¿¼ë¦¬ë§Œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”."]
                    }
            
            # SELECT ì¿¼ë¦¬ì¸ì§€ í™•ì¸
            if not sql_upper.startswith('SELECT'):
                return {
                    "is_valid": False,
                    "error_message": "SELECT ì¿¼ë¦¬ë§Œ í—ˆìš©ë©ë‹ˆë‹¤.",
                    "suggestions": ["SELECT ë¬¸ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”."]
                }
            
            return {
                "is_valid": True,
                "suggestions": ["ì¿¼ë¦¬ê°€ ìœ íš¨í•©ë‹ˆë‹¤."]
            }
            
        except Exception as e:
            return {
                "is_valid": False,
                "error_message": f"ì¿¼ë¦¬ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "suggestions": ["ì¿¼ë¦¬ ë¬¸ë²•ì„ í™•ì¸í•´ ì£¼ì„¸ìš”."]
            }
    
    def _generate_sql_with_metadata(self, question: str) -> Tuple[str, str, Dict[str, Any]]:
        """SQL ìƒì„± with ë©”íƒ€ë°ì´í„° (ë…¸íŠ¸ë¶ì˜ AdvancedSQLGenerator ê¸°ëŠ¥)"""
        start_time = time.time()
        self.generation_stats['total_requests'] += 1
        
        question_lower = question.lower().strip()
        self.logger.debug(f"SQL ìƒì„± ì‹œì‘: '{question}'")
        
        # íŒ¨í„´ ë§¤ì¹­ ì‹œë„
        for pattern, sql_template in self.query_patterns.items():
            if re.search(pattern, question_lower, re.IGNORECASE):
                self.logger.debug(f"íŒ¨í„´ ë§¤ì¹˜: {pattern}")
                self.generation_stats['pattern_matches'] += 1
                
                sql_query = sql_template.strip()
                explanation = self._get_explanation_for_pattern(pattern, question)
                generation_time = time.time() - start_time
                
                # ë³µì¡ë„ íŒë‹¨
                complexity = 'complex' if 'JOIN' in sql_query.upper() or 'GROUP BY' in sql_query.upper() else 'simple'
                
                metadata = {
                    'method': 'pattern_matching',
                    'complexity': complexity,
                    'generation_time': round(generation_time, 3),
                    'confidence': 0.9,
                    'pattern_used': pattern
                }
                
                return sql_query, explanation, metadata
        
        # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ fallback
        sql_query, explanation = self._get_fallback_query(question_lower)
        generation_time = time.time() - start_time
        
        metadata = {
            'method': 'fallback',
            'complexity': 'simple',
            'generation_time': round(generation_time, 3),
            'confidence': 0.5
        }
        
        return sql_query, explanation, metadata
    
    async def record_query_token_usage(
        self,
        user_id: str,
        query_id: str,
        token_usage: Dict[str, int],
        model_name: str,
        question: str,
        sql_query: str
    ):
        """ì¿¼ë¦¬ ì‹¤í–‰ ì‹œ í† í° ì‚¬ìš©ëŸ‰ì„ ê¸°ë¡í•©ë‹ˆë‹¤."""
        token_service = self._get_token_usage_service()
        if not token_service:
            return False
            
        try:
            # QueryAnalyticsì— í† í° ì‚¬ìš©ëŸ‰ê³¼ í•¨ê»˜ ì €ì¥
            from models.models import QueryAnalytics
            
            async with self.db_manager.get_session("app") as session:
                analytics_record = QueryAnalytics(
                    id=str(uuid.uuid4()),
                    query_id=query_id,
                    user_id=user_id,
                    question=question,
                    sql_query=sql_query,
                    execution_time=0.0,  # SQL ì‹¤í–‰ ì‹œê°„ê³¼ ë³„ë„ë¡œ ê´€ë¦¬
                    row_count=0,
                    success=True,
                    # í† í° ì‚¬ìš©ëŸ‰ ì •ë³´
                    prompt_tokens=token_usage.get("prompt_tokens", 0),
                    completion_tokens=token_usage.get("completion_tokens", 0),
                    total_tokens=token_usage.get("total_tokens", 0),
                    llm_model=model_name,
                    llm_cost_estimate=self._calculate_cost(token_usage, model_name)
                )
                
                session.add(analytics_record)
                
                # ì‚¬ìš©ìì˜ í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½ë„ ì—…ë°ì´íŠ¸
                await token_service._update_user_token_summary(
                    session, user_id, token_usage
                )
                
                self.logger.info(
                    f"í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡ ì™„ë£Œ - ì‚¬ìš©ì: {user_id}, ì´ í† í°: {token_usage.get('total_tokens', 0)}"
                )
                return True
                
        except Exception as e:
            self.logger.error(f"í† í° ì‚¬ìš©ëŸ‰ ê¸°ë¡ ì‹¤íŒ¨: {str(e)}")
            return False
    
    def _calculate_cost(self, token_usage: Dict[str, int], model_name: str) -> float:
        """ëª¨ë¸ë³„ í† í° ì‚¬ìš©ëŸ‰ì— ë”°ë¥¸ ë¹„ìš© ê³„ì‚°"""
        # GPT-4o ê¸°ì¤€ ê°€ê²© (2024ë…„ ê¸°ì¤€)
        pricing = {
            "gpt-4o": {"input": 0.005 / 1000, "output": 0.015 / 1000},  # per 1K tokens
            "gpt-35-turbo": {"input": 0.0015 / 1000, "output": 0.002 / 1000},
            "default": {"input": 0.002 / 1000, "output": 0.003 / 1000}
        }
        
        model_pricing = pricing.get(model_name.lower(), pricing["default"])
        
        input_cost = token_usage.get("prompt_tokens", 0) * model_pricing["input"]
        output_cost = token_usage.get("completion_tokens", 0) * model_pricing["output"]
        
        return round(input_cost + output_cost, 6)
