# ë¡œê¹… ì‹œìŠ¤í…œ ê°€ì´ë“œ

Text-to-SQL AI Agentì˜ í¬ê´„ì ì¸ ë¡œê¹… ì‹œìŠ¤í…œ ì‚¬ìš©ë²•ê³¼ êµ¬ì¡°ì— ëŒ€í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“Š ë¡œê¹… ì‹œìŠ¤í…œ êµ¬ì¡°

### ë¡œê·¸ íŒŒì¼ êµ¬ì¡°
```
logs/
â”œâ”€â”€ app.log                 # ì „ì²´ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œê·¸ (JSON í˜•ì‹)
â”œâ”€â”€ error.log              # ì—ëŸ¬ ì „ìš© ë¡œê·¸
â”œâ”€â”€ api_requests.log       # API ìš”ì²­/ì‘ë‹µ ë¡œê·¸
â”œâ”€â”€ sql_queries.log        # SQL ì¿¼ë¦¬ ì‹¤í–‰ ë¡œê·¸
â”œâ”€â”€ chat_sessions.log      # ì±„íŒ… ì„¸ì…˜ ê´€ë ¨ ë¡œê·¸
â”œâ”€â”€ authentication.log     # ì¸ì¦ ê´€ë ¨ ë¡œê·¸
â””â”€â”€ report_YYYYMMDD_HHMMSS.json  # ë¶„ì„ ë¦¬í¬íŠ¸
```

### ë¡œê·¸ í¬ë§·
ëª¨ë“  ë¡œê·¸ëŠ” JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ë©° ë‹¤ìŒ í•„ë“œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:

```json
{
    "timestamp": "2024-01-15T14:30:45.123456",
    "level": "INFO",
    "logger": "backend.api.v1.endpoints.chat",
    "message": "SQL ì¿¼ë¦¬ ì‹¤í–‰ ì™„ë£Œ",
    "module": "chat",
    "function": "process_chat_query",
    "line": 456,
    "user_id": "user123",
    "session_id": "session456",
    "request_id": "req789",
    "sql_query": "SELECT * FROM products",
    "execution_time": 0.234
}
```

## ğŸ”§ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜
```bash
# ë¡œê¹… ë ˆë²¨ ì„¤ì •
LOG_LEVEL=INFO

# íŒŒì¼ ë¡œê¹… í™œì„±í™”
LOG_TO_FILE=true

# ë¡œê·¸ íŒŒì¼ ìµœëŒ€ í¬ê¸° (MB)
LOG_FILE_MAX_SIZE_MB=10

# ë°±ì—… íŒŒì¼ ê°œìˆ˜
LOG_FILE_BACKUP_COUNT=5

# JSON ë¡œê¹… í™œì„±í™”
ENABLE_JSON_LOGGING=true

# ê° ë¡œê·¸ íƒ€ì… í™œì„±í™”/ë¹„í™œì„±í™”
LOG_SQL_QUERIES=true
LOG_API_REQUESTS=true
LOG_CHAT_MESSAGES=true
LOG_AUTH_EVENTS=true

# ë¡œê·¸ ë³´ê´€ ê¸°ê°„ (ì¼)
LOG_RETENTION_DAYS=30

# ì„±ëŠ¥ ê´€ë ¨ ì„¤ì •
LOG_SLOW_QUERIES=true
SLOW_QUERY_THRESHOLD_SECONDS=1.0
LOG_PERFORMANCE_METRICS=true

# ë¯¼ê°í•œ ë°ì´í„° ë§ˆìŠ¤í‚¹ íŒ¨í„´
SENSITIVE_DATA_PATTERNS=["password", "token", "secret", "key"]
```

## ğŸš€ ë¡œê·¸ ê´€ë¦¬ ë„êµ¬ ì‚¬ìš©ë²•

í¸ì˜ ìŠ¤í¬ë¦½íŠ¸ `manage_logs.py`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œê·¸ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

### ê¸°ë³¸ ì‚¬ìš©ë²•
```bash
# ë¡œê·¸ íŒŒì¼ ìƒíƒœ í™•ì¸
python manage_logs.py status

# ìµœê·¼ 24ì‹œê°„ ë¡œê·¸ ë¶„ì„
python manage_logs.py analyze

# ìƒì„¸ ë¶„ì„ ì •ë³´ í¬í•¨
python manage_logs.py analyze --hours 48 --detailed

# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
python manage_logs.py tail --type app

# íŠ¹ì • ë¡œê·¸ íƒ€ì… ëª¨ë‹ˆí„°ë§
python manage_logs.py tail --type sql --lines 100

# ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
python manage_logs.py report --hours 24 --output daily_report.json

# ì˜¤ë˜ëœ ë¡œê·¸ ì •ë¦¬ (30ì¼ ì´ì „)
python manage_logs.py cleanup --days 30

# ì‚­ì œ ì „ í™•ì¸ (dry-run)
python manage_logs.py cleanup --days 30 --dry-run
```

### ê³ ê¸‰ ë¶„ì„
```bash
# íŠ¹ì • ê¸°ê°„ ì—ëŸ¬ ë¶„ì„
python -c "
from utils.log_analyzer import LogAnalyzer
analyzer = LogAnalyzer()
errors = analyzer.analyze_errors(hours=72)
print(f'ì´ ì—ëŸ¬: {errors[\"total_errors\"]}ê°œ')
for module, count in errors['error_by_module'].items():
    print(f'{module}: {count}ê°œ')
"

# API ì„±ëŠ¥ ë¶„ì„
python -c "
from utils.log_analyzer import LogAnalyzer
analyzer = LogAnalyzer()
api_perf = analyzer.analyze_api_performance(hours=24)
print(f'í‰ê·  ì‘ë‹µì‹œê°„: {api_perf[\"avg_response_time_ms\"]:.1f}ms')
print(f'ëŠë¦° ìš”ì²­: {len(api_perf[\"slow_requests\"])}ê°œ')
"
```

## ğŸ“ˆ ë¡œê¹… ëª¨ë²” ì‚¬ë¡€

### 1. êµ¬ì¡°í™”ëœ ë¡œê¹…
```python
import logging
from utils.logging_config import RequestLogger, SQLLogger, ChatLogger, AuthLogger

logger = logging.getLogger(__name__)

# ê¸°ë³¸ ë¡œê¹…
logger.info("ì‘ì—… ì™„ë£Œ", extra={
    'user_id': user_id,
    'operation': 'create_user',
    'duration': execution_time
})

# íŠ¹í™”ëœ ë¡œê±° ì‚¬ìš©
RequestLogger.log_request(
    request_id=request_id,
    method="POST",
    path="/api/v1/users",
    user_id=user_id,
    body={"email": "user@example.com"}
)

SQLLogger.log_query_execution(
    query="SELECT * FROM users WHERE id = ?",
    execution_time=0.123,
    result_count=1,
    user_id=user_id,
    success=True
)
```

### 2. ì—ëŸ¬ ë¡œê¹…
```python
try:
    # ìœ„í—˜í•œ ì‘ì—…
    result = await some_operation()
except Exception as e:
    logger.error(
        f"ì‘ì—… ì‹¤íŒ¨: {str(e)}",
        extra={
            'user_id': user_id,
            'operation': 'some_operation',
            'error_details': str(e)
        },
        exc_info=True  # ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤ í¬í•¨
    )
```

### 3. ì„±ëŠ¥ ë¡œê¹…
```python
import time

start_time = time.time()
try:
    result = await expensive_operation()
    execution_time = time.time() - start_time
    
    logger.info(
        f"ì‘ì—… ì™„ë£Œ - ì‹œê°„: {execution_time:.3f}s",
        extra={
            'operation': 'expensive_operation',
            'execution_time': execution_time,
            'result_size': len(result)
        }
    )
finally:
    # í•­ìƒ ì‹¤í–‰ ì‹œê°„ ê¸°ë¡
    pass
```

## ğŸ” ë¡œê·¸ ë¶„ì„ ì˜ˆì‹œ

### 1. ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
```bash
# ìµœê·¼ 24ì‹œê°„ ì—ëŸ¬ ë¶„ì„
python manage_logs.py analyze --hours 24

# ê²°ê³¼ ì˜ˆì‹œ:
# ğŸ“ˆ ì—ëŸ¬ ë¶„ì„:
#   - ì´ ì—ëŸ¬: 12ê°œ
#   - ëª¨ë“ˆë³„ ì—ëŸ¬:
#     * sql_agent: 5ê°œ
#     * auth_service: 3ê°œ
#     * chat: 4ê°œ
```

### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```bash
# API ì„±ëŠ¥ ë¶„ì„
python manage_logs.py analyze --detailed

# ê²°ê³¼ ì˜ˆì‹œ:
# ğŸš€ API ì„±ëŠ¥ ë¶„ì„:
#   - ì´ ìš”ì²­: 1,234ê°œ
#   - í‰ê·  ì‘ë‹µì‹œê°„: 145.3ms
#   - ìµœëŒ€ ì‘ë‹µì‹œê°„: 2,456ms
#   - ëŠë¦° ìš”ì²­: 8ê°œ
#
# â±ï¸ ëŠë¦° API ìš”ì²­:
#   - /api/v1/chat/sessions/123/query: 2456ms
#   - /api/v1/auth/login: 1892ms
```

### 3. ì‚¬ìš©ì í™œë™ ë¶„ì„
```python
from utils.log_analyzer import LogAnalyzer

analyzer = LogAnalyzer()
user_activity = analyzer.analyze_user_activity(hours=24)

print(f"í™œì„± ì‚¬ìš©ì: {user_activity['total_active_users']}ëª…")
print(f"ì´ ë¡œê·¸ì¸: {user_activity['total_logins']}íšŒ")
print(f"ì´ ì±„íŒ… ë©”ì‹œì§€: {user_activity['total_chat_messages']}ê°œ")

# ê°€ì¥ í™œì„±ì ì¸ ì‚¬ìš©ì í™•ì¸
for user_id, activity in user_activity['top_active_users'].items():
    print(f"ì‚¬ìš©ì {user_id}: {activity['chat_messages']}ê°œ ë©”ì‹œì§€, {activity['login_count']}íšŒ ë¡œê·¸ì¸")
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë¡œê·¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠëŠ” ê²½ìš°
1. `logs/` ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
2. ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ í™•ì¸
3. `LOG_TO_FILE=true` ì„¤ì • í™•ì¸

### ë¡œê·¸ íŒŒì¼ì´ ë„ˆë¬´ í° ê²½ìš°
1. `LOG_FILE_MAX_SIZE_MB` ê°’ ì¡°ì •
2. `LOG_FILE_BACKUP_COUNT` ì¦ê°€
3. ìë™ ì •ë¦¬ ìŠ¤ì¼€ì¤„ ì„¤ì •:
   ```bash
   # crontabì— ì¶”ê°€ (ë§¤ì¼ ìì • 30ì¼ ì´ì „ ë¡œê·¸ ì •ë¦¬)
   0 0 * * * cd /path/to/backend && python manage_logs.py cleanup --days 30
   ```

### ì„±ëŠ¥ ì˜í–¥ ìµœì†Œí™”
1. í”„ë¡œë•ì…˜ì—ì„œëŠ” `LOG_LEVEL=INFO` ë˜ëŠ” `WARNING` ì‚¬ìš©
2. `DEBUG_SQL_QUERIES=false` ì„¤ì •
3. `LOG_REQUEST_BODY=false` (ë¯¼ê°í•œ ì •ë³´ í¬í•¨ ì‹œ)

## ğŸ“Š ëŒ€ì‹œë³´ë“œ ë° ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ ê¸°ë°˜ ëŒ€ì‹œë³´ë“œ ìƒì„±
```python
# ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì˜ˆì‹œ
from utils.log_analyzer import LogAnalyzer
import json

analyzer = LogAnalyzer()
daily_report = analyzer.generate_report(hours=24)

# ì£¼ìš” ë©”íŠ¸ë¦­ ì¶”ì¶œ
metrics = {
    'total_errors': daily_report['error_analysis']['total_errors'],
    'avg_response_time': daily_report['api_performance']['avg_response_time_ms'],
    'total_queries': daily_report['sql_analysis']['total_queries'],
    'active_users': daily_report['user_activity']['total_active_users']
}

print(json.dumps(metrics, indent=2))
```

### ì•Œë¦¼ ì„¤ì •
```python
# ì—ëŸ¬ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ì•Œë¦¼
def check_error_threshold():
    analyzer = LogAnalyzer()
    errors = analyzer.analyze_errors(hours=1)
    
    if errors['total_errors'] > 10:  # 1ì‹œê°„ì— 10ê°œ ì´ìƒ ì—ëŸ¬
        send_alert(f"ë†’ì€ ì—ëŸ¬ìœ¨ ê°ì§€: {errors['total_errors']}ê°œ/ì‹œê°„")
```

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **ë¯¼ê°í•œ ë°ì´í„° ë§ˆìŠ¤í‚¹**: ë¹„ë°€ë²ˆí˜¸, í† í° ë“± ìë™ ë§ˆìŠ¤í‚¹
2. **ë¡œê·¸ íŒŒì¼ ê¶Œí•œ**: ì½ê¸° ì „ìš©ìœ¼ë¡œ ì„¤ì •
3. **ë¡œê·¸ ì „ì†¡**: í•„ìš”ì‹œ TLSë¡œ ì•”í˜¸í™”ëœ ì—°ê²° ì‚¬ìš©
4. **ë³´ê´€ ê¸°ê°„**: ê·œì •ì— ë”°ë¥¸ ì ì ˆí•œ ë³´ê´€ ê¸°ê°„ ì„¤ì •

## ğŸ“ ë¡œê·¸ ë¶„ì„ ìë™í™”

### ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# weekly_report.sh

cd /path/to/backend

# ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±
python manage_logs.py report --hours 168 --output "reports/weekly_$(date +%Y%m%d).json"

# ì´ì „ ì£¼ì™€ ë¹„êµ
python -c "
import json
from datetime import datetime, timedelta

# í˜„ì¬ ì£¼ê°„ ë¦¬í¬íŠ¸ ë¡œë“œ
with open('reports/weekly_$(date +%Y%m%d).json') as f:
    current = json.load(f)

print(f'ì´ë²ˆ ì£¼ ì—ëŸ¬: {current[\"error_analysis\"][\"total_errors\"]}ê°œ')
print(f'ì´ë²ˆ ì£¼ í‰ê·  ì‘ë‹µì‹œê°„: {current[\"api_performance\"][\"avg_response_time_ms\"]:.1f}ms')
"
```

ì´ ë¡œê¹… ì‹œìŠ¤í…œì„ í†µí•´ Text-to-SQL AI Agentì˜ ëª¨ë“  í™œë™ì„ ì²´ê³„ì ìœ¼ë¡œ ì¶”ì í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 